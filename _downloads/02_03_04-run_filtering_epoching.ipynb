{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\nBlabla\n======================\n\nblabla\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "import os\nimport os.path as op\nimport numpy as np\n\nimport mne\nfrom mne.io.constants import FIFF\nfrom mne.parallel import parallel_func\nfrom mne.preprocessing import ICA, create_ecg_epochs\n\nfrom autoreject import GlobalAutoReject, validation_curve\n\nfrom config import study_path, meg_dir, N_JOBS\nautoreject = True\nif not op.exists(meg_dir):\n    os.mkdir(meg_dir)\n\nevents_id = {\n    'famous/first': 5,\n    'famous/immediate': 6,\n    'famous/long': 7,\n    'unfamiliar/first': 13,\n    'unfamiliar/immediate': 14,\n    'unfamiliar/long': 15,\n    'scrambled/first': 17,\n    'scrambled/immediate': 18,\n    'scrambled/long': 19,\n}\n\ntmin, tmax = -0.2, 0.8\nreject = dict(grad=4000e-13, mag=4e-12, eog=180e-6)\n#baseline = (-0.2, 00.)\nbaseline = None\n\ndef run_process(subject_id):\n    subject = \"sub%03d\" % subject_id\n    data_path = op.join(meg_dir, subject)\n    #raw_fname_out = op.join(data_path, 'run_%02d_filt_sss_raw.fif')\n\n    # # Get all bad channels\n    all_bads = []\n    all_epochs = []\n    for run in range(1, 7):\n        bads = list()\n        bad_name = op.join(data_path, 'bads', 'run_%02d_raw_tr.fif_bad' % run)\n\n        if os.path.exists(bad_name):\n            with open(bad_name) as f:\n                for line in f:\n                    bads.append(line.strip())\n        #     bads = np.loadtxt(data_path + '/MaxFilterOutput/run_%02d_bad.txt' % run)\n        #     bads = np.unique(bads.ravel())\n        #     bads = ['MEG%d' % b for b in bads]\n        all_bads += [bad for bad in bads if bad not in all_bads]\n\n    for run in range(1, 7):\n        raw_fname_in = op.join(study_path, 'MEG', subject,\n                               'run_%02d_cropped_sss.fif')\n        if not os.path.exists(raw_fname_in % run):\n            raw_fname_in = op.join(study_path, 'MEG', subject,\n                                   'run_%02d_new_sss.fif')\n        if not os.path.exists(raw_fname_in % run):\n            raw_fname_in = op.join(study_path, 'ds117', subject,\n                                   'MEG', 'run_%02d_sss.fif')\n        raw_in = raw_fname_in % run\n        raw = mne.io.read_raw_fif(raw_in, preload=True)\n        #raw_out = raw_fname_out % run\n        if not op.exists(op.join(meg_dir, subject)):\n            os.mkdir(op.join(meg_dir, subject))\n\n\n        raw.filter(1, 40, n_jobs=N_JOBS)\n        #raw.filter(1, 40, method='iir', n_jobs=1, h_trans_bandwidth='auto', l_trans_bandwidth='auto', verbose='INFO')\n        #raw.save(raw_out, overwrite=True)\n        events = mne.find_events(raw, stim_channel='STI101',\n                                 consecutive='increasing',\n                                 min_duration=0.003, verbose=True)\n\n        # Events\n        print(\"S %s - R %s\" % (subject, run))\n\n        #fname_events = op.join(data_path, 'run_%02d_filt_sss-eve.fif' % run)\n        #mne.write_events(fname_events, events)\n        for idx, proj in enumerate(raw.info['projs']):\n            if proj['kind'] == FIFF.FIFFV_MNE_PROJ_ITEM_EEG_AVREF:\n                proj_idx = idx\n                break\n        raw.del_proj(proj_idx)  # remove EEG average ref\n\n        raw.set_channel_types({'EEG061': 'eog',\n                               'EEG062': 'eog',\n                               'EEG063': 'ecg',\n                               'EEG064': 'misc'})  # EEG064 free floating el.\n        raw.rename_channels({'EEG061': 'EOG061',\n                             'EEG062': 'EOG062',\n                             'EEG063': 'ECG063'})\n\n        ica_name = op.join(study_path, 'MEG', subject, 'run_%02d-ica.fif' % run)\n        if os.path.exists(ica_name):\n            ica = mne.preprocessing.read_ica(ica_name)\n        else:\n\n            ica = ICA(method='fastica', random_state=42, n_components=0.95)\n            picks = mne.pick_types(raw.info, meg=True, eeg=False, eog=False,\n                                   stim=False, exclude='bads')\n            ica.fit(raw, picks=picks, reject=dict(grad=4000e-13, mag=4e-12))\n            ica.save(ica_name)\n        n_max_ecg = 3\n        ecg_epochs = create_ecg_epochs(raw, tmin=-.5, tmax=.5)\n        ecg_inds, scores_ecg = ica.find_bads_ecg(ecg_epochs, method='ctps',\n                                                 threshold=0.8)\n        ica.exclude += ecg_inds[:n_max_ecg]\n\n        # Epoching\n        print \"Epoching - Run %s\" % run\n\n        eog_events = mne.preprocessing.find_eog_events(raw)\n        eog_events[:, 0] -= int(0.25 * raw.info['sfreq'])\n        annotations = mne.Annotations(eog_events[:, 0] / raw.info['sfreq'],\n                                      np.repeat(0.5, len(eog_events)),\n                                      'BAD_blink', raw.info['meas_date'])\n        raw.annotations = annotations  # Remove epochs with blinks\n\n        delay = int(0.0345 * raw.info['sfreq'])\n\n        #events = mne.read_events(op.join(data_path,\n        #                                 'run_%02d_filt_sss-eve.fif' % run))\n\n        events[:, 0] = events[:, 0] + delay\n\n        # Add bad channels (only needed for non SSS data)\n        # if not (\"sss\" in raw.info['filename']):\n        #     raw.info['bads'] = all_bads\n        #     exclude = all_bads\n        # exclude = []  # XXX\n        raw.info['bads'] = all_bads\n        raw.interpolate_bads()\n        raw.add_eeg_average_proj()\n        exclude = []\n        # exclude = all_bads\n\n        picks = mne.pick_types(raw.info, meg=True, eeg=True, stim=True,\n                               eog=True, exclude=exclude)\n\n        if autoreject:\n            epochs = mne.Epochs(raw, events, events_id, tmin, tmax, proj=True,\n                                picks=picks, baseline=baseline, preload=True,\n                                reject=None)\n            reject = dict()\n            param_range = np.linspace(400e-15, 20000e-15, 30)\n            _, test_scores = validation_curve(\n                GlobalAutoReject(), epochs.copy().pick_types(meg='mag'),\n                y=None, param_name=\"thresh\", param_range=param_range, cv=5,\n                n_jobs=N_JOBS)\n\n            test_scores = -test_scores.mean(axis=1)\n            reject['mag'] = param_range[np.argmin(test_scores)]\n\n\n            param_range = np.linspace(400e-13, 20000e-13, 30)\n            _, test_scores = validation_curve(\n                GlobalAutoReject(), epochs.copy().pick_types(meg='grad'),\n                y=None, param_name=\"thresh\", param_range=param_range, cv=5,\n                n_jobs=N_JOBS)\n            test_scores = -test_scores.mean(axis=1)\n            reject['grad'] = param_range[np.argmin(test_scores)]\n\n            param_range = np.linspace(20e-7, 400e-6, 30)\n            _, test_scores = validation_curve(\n                GlobalAutoReject(), epochs.copy().pick_types(meg=False,\n                                                             eeg=True),\n                y=None, param_name=\"thresh\", param_range=param_range, cv=5,\n                n_jobs=N_JOBS)\n            test_scores = -test_scores.mean(axis=1)\n            reject['grad'] = param_range[np.argmin(test_scores)]\n            epochs.drop_bad(reject=reject)\n            #ar = LocalAutoRejectCV(method='random_search')\n            #epochs_eeg = ar.fit_transform(epochs.copy().pick_types(eeg=True, meg=False))\n        else:\n            # Read epochs\n            epochs = mne.Epochs(raw, events, events_id, tmin, tmax, proj=True,\n                                picks=picks, baseline=baseline, preload=True,\n                                reject=reject)\n        ica.apply(epochs)\n        all_epochs.append(epochs)\n\n    epochs = mne.epochs.concatenate_epochs(all_epochs)\n    epochs.save(op.join(data_path, '%s-epo.fif' % subject))\n\n    evoked_famous = epochs['famous'].average()\n    evoked_scrambled = epochs['scrambled'].average()\n    evoked_unfamiliar = epochs['unfamiliar'].average()\n\n    # Simplify comment\n    evoked_famous.comment = 'famous'\n    evoked_scrambled.comment = 'scrambled'\n    evoked_unfamiliar.comment = 'unfamiliar'\n\n    contrast = mne.combine_evoked([evoked_famous, evoked_unfamiliar,\n                                   evoked_scrambled], weights=[0.5, 0.5, -1.])\n    contrast.comment = 'contrast'\n    faces = mne.combine_evoked([evoked_famous, evoked_unfamiliar])\n    faces.comment = 'faces'\n\n    mne.evoked.write_evokeds(op.join(data_path, '%s-ave.fif' % subject),\n                             [evoked_famous, evoked_scrambled,\n                              evoked_unfamiliar, contrast, faces])\n\n    # take care of noise cov\n    cov = mne.compute_covariance(epochs, tmin=tmin, tmax=0)\n    cov.save(op.join(data_path, '%s-cov.fif' % subject))\n\n\nparallel, run_func, _ = parallel_func(run_process, n_jobs=N_JOBS)\nparallel(run_func(subject_id) for subject_id in range(1, 20))"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.12", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}