{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\nBlabla\n======================\n\nblabla\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "import os.path as op\nimport numpy as np\n\nimport mne\nfrom mne.minimum_norm import apply_inverse, read_inverse_operator\n\nfrom library.config import meg_dir, subjects_dir, spacing\n\nstcs = list()\ncontrasts = list()\nfams = list()\nunfams = list()\nscrambs = list()\nexclude = []\n#exclude = [1, 5, 16]  # Excluded subjects\nfaces = list()\nscrambled = list()\nch_names = list()\nfor run in range(1, 20):\n    if run in exclude:\n        continue\n    subject = \"sub%03d\" % run\n    print(\"processing subject: %s\" % subject)\n    data_path = op.join(meg_dir, subject)\n\n    evokeds = mne.read_evokeds(op.join(meg_dir, subject,\n                                       '%s-ave.fif' % subject))\n    fams.append(evokeds[0])\n    scrambs.append(evokeds[1])\n    unfams.append(evokeds[2])\n    contrast = mne.combine_evoked(evokeds[:3], weights=[0.5, -1, 0.5])\n    fname_inv = op.join(data_path, '%s-meg-%s-inv.fif' % (subject, spacing))\n    inv = read_inverse_operator(fname_inv)\n\n    # Compute inverse solution\n    snr = 3.0\n    lambda2 = 1.0 / snr ** 2\n    stc = apply_inverse(contrast, inv, lambda2, \"dSPM\", pick_ori=None)\n    stcs.append(stc.morph(subject_from=subject, subject_to='fsaverage',\n                          subjects_dir=subjects_dir))\n    contrasts.append(contrast)\n\n    eeg_fams = evokeds[0]\n    eeg_unfams = evokeds[2]\n    eeg_fams.pick_types(meg=False, eeg=True)\n    eeg_unfams.pick_types(meg=False, eeg=True)\n\n    scrambled.append(evokeds[1])\n    faces.append(mne.combine_evoked([eeg_fams, eeg_unfams]))\n    if len(ch_names) == 0:\n        ch_names = faces[-1].ch_names\n    else:\n        ch_names = np.intersect1d(ch_names, faces[-1].ch_names)\n\n\ndata = np.average([s.data for s in stcs], axis=0)\n\nstc = mne.SourceEstimate(data, stcs[0].vertices, stcs[0].tmin, stcs[0].tstep)\nstc.save(op.join(meg_dir, 'contrast-average'))\n\nfor i in range(len(faces)):  # pick good channels\n    fams[i] = fams[i].pick_channels(ch_names)\n    unfams[i] = unfams[i].pick_channels(ch_names)\n    faces[i] = faces[i].pick_channels(ch_names)\n    scrambled[i] = scrambled[i].pick_channels(ch_names)\n\nfams = mne.combine_evoked(fams)\nfams.save(op.join(meg_dir, 'eeg_famous-ave.fif'))\nunfams = mne.combine_evoked(unfams)\nunfams.save(op.join(meg_dir, 'eeg_unfamiliar-ave.fif'))\nscrambled = mne.combine_evoked(scrambled)\nscrambled.save(op.join(meg_dir, 'eeg_scrambled-ave.fif'))"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.12", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}